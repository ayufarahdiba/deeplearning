{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AlexNet.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "OH_brD3O0Opd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.layers import GlobalAveragePooling2D, Multiply, Dense\n",
        "from keras import backend as K\n",
        "\n",
        "def SqueezeExcite(x, ratio=16, name=''):\n",
        "    nb_chan = K.int_shape(x)[-1]\n",
        "\n",
        "    y = GlobalAveragePooling2D(name='{}_se_avg'.format(name))(x)\n",
        "    y = Dense(nb_chan // ratio, activation='relu', name='{}_se_den1'.format(name))(y)\n",
        "    y = Dense(nb_chan, activation='sigmoid', name='{}_se_den2'.format(name))(y)\n",
        "\n",
        "    y = Multiply(name='{}_se_mul'.format(name))([x, y])\n",
        "    return y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "waPQBrfQ9Yuj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential  \n",
        "from keras.layers import Dense, Dropout, Flatten ,Conv2D, MaxPooling2D,Input\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.layers.core import Dense, Dropout, Activation\n",
        "from keras.models import Model \n",
        "from keras import backend as K\n",
        "from keras.regularizers import l2\n",
        "from keras.optimizers import *"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iSwx3GRa9thz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def conv_block(n_class=10, init_lr = 0.01):\n",
        "    # layer 1\n",
        "    inputs = Input((28,28,1))\n",
        "    conv1 = Conv2D(filters=96, input_shape=(224,224,3), kernel_size=(11,11),activation = 'relu',strides=(4,4), padding='same')(inputs)\n",
        "    conv1 = Dropout(0.2)(conv1)\n",
        "    conv1 = SqueezeExcite(conv1, ratio=16, name='conv1')\n",
        "    pool1 = MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='same')(conv1)\n",
        "    \n",
        "    # layer 2\n",
        "    conv2 = Conv2D(filters=256,kernel_size=(5,5),activation ='relu',strides=(1,1), padding='same')(pool1)\n",
        "    conv2 = Dropout(0.2)(conv2)\n",
        "    conv2 = SqueezeExcite(conv2, ratio=16, name='conv2')\n",
        "    pool2 = MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='same')(conv2)\n",
        "    \n",
        "    # layer 3\n",
        "    conv3 = Conv2D(filters=512,kernel_size=(3,3),activation = 'relu',strides=(4,4), padding='same')(pool2)\n",
        "    conv3 = Dropout(0.2)(conv3)\n",
        "    conv3 = SqueezeExcite(conv3, ratio=16, name='conv3')\n",
        "    pool3 = MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='same')(conv1)\n",
        "    \n",
        "    # layer 4\n",
        "    conv4 = Conv2D(filters=1024,kernel_size=(3,3),activation = 'relu',strides=(4,4), padding='same')(pool3)\n",
        "    conv4 = Dropout(0.2)(conv4)\n",
        "    conv4 = SqueezeExcite(conv4, ratio=16, name='conv4')\n",
        "    \n",
        "    # layer 5\n",
        "    conv5 = Conv2D(filters=1024,kernel_size=(3,3),activation = 'relu',strides=(4,4), padding='same')(conv4)\n",
        "    conv5 = Dropout(0.2)(conv5)\n",
        "    conv5 = SqueezeExcite(conv5, ratio=16, name='conv5')\n",
        "    pool5 = MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='same')(conv5)\n",
        "    \n",
        "    # layer 6\n",
        "    conv6 = Flatten() (pool5)\n",
        "    conv6 = Dense(3072) (conv6)\n",
        "    conv6 = Activation('relu') (conv6)\n",
        "    conv6 = Dropout(0.4)(conv6)\n",
        "    \n",
        "    \n",
        "    # last o/p \n",
        "    conv7 = Dense(n_class)(conv6)\n",
        "    conv7 = Activation('softmax')(conv7)\n",
        "    \n",
        "    model = Model(input=inputs, output=conv7)\n",
        "    \n",
        "    model.compile(loss=\"categorical_crossentropy\", optimizer= Adam(lr=init_lr) , metrics=['accuracy'] )\n",
        "    \n",
        "    \n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4-Cc2xbJ9xTB",
        "colab_type": "code",
        "outputId": "d5ad1a1a-baa9-4c80-b50d-30bf0967b3c9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386
        }
      },
      "source": [
        "model = conv_block()\n",
        "print(model.summary)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "<bound method Network.summary of <keras.engine.training.Model object at 0x7fa765a2feb8>>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:43: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"ac...)`\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jvrnTfLl92LL",
        "colab_type": "code",
        "outputId": "836d415a-b0de-46f7-a1ab-74a793ddcc20",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from keras.datasets import mnist\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.utils import np_utils\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "print(y_test.shape)\n",
        "img_rows, img_cols = 28, 28\n",
        "nb_class = 10\n",
        "x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
        "x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train/= 255\n",
        "x_test/= 255\n",
        "y_train = np_utils.to_categorical(y_train, nb_class)\n",
        "y_test = np_utils.to_categorical(y_test, nb_class)\n",
        "gen = ImageDataGenerator(rotation_range = 8,width_shift_range=0.08,shear_range= 0.3, height_shift_range= 0.08,zoom_range=0.08)\n",
        "test_gen = ImageDataGenerator()\n",
        "print(x_test.shape)                                                                                                                                         \n",
        "print(y_test.shape)\n",
        "print(x_train.shape)\n",
        "print(y_train.shape)\n",
        "train_generator = gen.flow(x_train,y_train,batch_size =4)\n",
        "test_generator = test_gen.flow(x_test,y_test,batch_size = 4)\n",
        "model.fit_generator(train_generator,steps_per_epoch =60000//64, epochs=50,validation_data= test_generator , validation_steps= 10000//64)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "(10000,)\n",
            "(10000, 28, 28, 1)\n",
            "(10000, 10)\n",
            "(60000, 28, 28, 1)\n",
            "(60000, 10)\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Epoch 1/50\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "937/937 [==============================] - 352s 376ms/step - loss: 2.3246 - acc: 0.1123 - val_loss: 2.3043 - val_acc: 0.1010\n",
            "Epoch 2/50\n",
            "937/937 [==============================] - 352s 375ms/step - loss: 2.3047 - acc: 0.1115 - val_loss: 2.3035 - val_acc: 0.1170\n",
            "Epoch 3/50\n",
            "937/937 [==============================] - 349s 373ms/step - loss: 2.3062 - acc: 0.1083 - val_loss: 2.3036 - val_acc: 0.0978\n",
            "Epoch 4/50\n",
            "937/937 [==============================] - 349s 373ms/step - loss: 2.3036 - acc: 0.1107 - val_loss: 2.2990 - val_acc: 0.1330\n",
            "Epoch 5/50\n",
            "937/937 [==============================] - 354s 378ms/step - loss: 2.3060 - acc: 0.1027 - val_loss: 2.3029 - val_acc: 0.1250\n",
            "Epoch 6/50\n",
            "937/937 [==============================] - 352s 375ms/step - loss: 2.3051 - acc: 0.0982 - val_loss: 2.3037 - val_acc: 0.0913\n",
            "Epoch 7/50\n",
            "937/937 [==============================] - 350s 373ms/step - loss: 2.3032 - acc: 0.1059 - val_loss: 2.3051 - val_acc: 0.1074\n",
            "Epoch 8/50\n",
            "937/937 [==============================] - 351s 375ms/step - loss: 2.3054 - acc: 0.1014 - val_loss: 2.3074 - val_acc: 0.1106\n",
            "Epoch 9/50\n",
            "937/937 [==============================] - 352s 376ms/step - loss: 2.3052 - acc: 0.1054 - val_loss: 2.3147 - val_acc: 0.0946\n",
            "Epoch 10/50\n",
            "937/937 [==============================] - 351s 375ms/step - loss: 2.3048 - acc: 0.1083 - val_loss: 2.3027 - val_acc: 0.0833\n",
            "Epoch 11/50\n",
            "937/937 [==============================] - 350s 373ms/step - loss: 2.3049 - acc: 0.1003 - val_loss: 2.3057 - val_acc: 0.0929\n",
            "Epoch 12/50\n",
            "937/937 [==============================] - 349s 373ms/step - loss: 2.3059 - acc: 0.1086 - val_loss: 2.3114 - val_acc: 0.0785\n",
            "Epoch 13/50\n",
            "937/937 [==============================] - 349s 373ms/step - loss: 2.3042 - acc: 0.1105 - val_loss: 2.3029 - val_acc: 0.1106\n",
            "Epoch 14/50\n",
            "937/937 [==============================] - 348s 372ms/step - loss: 2.3048 - acc: 0.0985 - val_loss: 2.3052 - val_acc: 0.1234\n",
            "Epoch 15/50\n",
            "937/937 [==============================] - 349s 373ms/step - loss: 2.3057 - acc: 0.1046 - val_loss: 2.3114 - val_acc: 0.0929\n",
            "Epoch 16/50\n",
            "937/937 [==============================] - 353s 377ms/step - loss: 2.3036 - acc: 0.1086 - val_loss: 2.2974 - val_acc: 0.1394\n",
            "Epoch 17/50\n",
            "937/937 [==============================] - 350s 374ms/step - loss: 2.3051 - acc: 0.1054 - val_loss: 2.3043 - val_acc: 0.1010\n",
            "Epoch 18/50\n",
            "937/937 [==============================] - 351s 375ms/step - loss: 2.3050 - acc: 0.1083 - val_loss: 2.3053 - val_acc: 0.0994\n",
            "Epoch 19/50\n",
            "937/937 [==============================] - 349s 372ms/step - loss: 2.3054 - acc: 0.1067 - val_loss: 2.3060 - val_acc: 0.1106\n",
            "Epoch 20/50\n",
            "937/937 [==============================] - 351s 375ms/step - loss: 2.3050 - acc: 0.1078 - val_loss: 2.3106 - val_acc: 0.1106\n",
            "Epoch 21/50\n",
            "937/937 [==============================] - 350s 374ms/step - loss: 2.3051 - acc: 0.1041 - val_loss: 2.3020 - val_acc: 0.1042\n",
            "Epoch 22/50\n",
            "937/937 [==============================] - 351s 374ms/step - loss: 2.3053 - acc: 0.1134 - val_loss: 2.3076 - val_acc: 0.1026\n",
            "Epoch 23/50\n",
            "937/937 [==============================] - 351s 375ms/step - loss: 2.3056 - acc: 0.1062 - val_loss: 2.2991 - val_acc: 0.1186\n",
            "Epoch 24/50\n",
            "937/937 [==============================] - 350s 373ms/step - loss: 2.3045 - acc: 0.1105 - val_loss: 2.2986 - val_acc: 0.1106\n",
            "Epoch 25/50\n",
            "937/937 [==============================] - 351s 374ms/step - loss: 2.3047 - acc: 0.1073 - val_loss: 2.2975 - val_acc: 0.1314\n",
            "Epoch 26/50\n",
            "937/937 [==============================] - 350s 374ms/step - loss: 2.3058 - acc: 0.1086 - val_loss: 2.3013 - val_acc: 0.1106\n",
            "Epoch 27/50\n",
            "937/937 [==============================] - 350s 374ms/step - loss: 2.3040 - acc: 0.1059 - val_loss: 2.3126 - val_acc: 0.0817\n",
            "Epoch 28/50\n",
            "937/937 [==============================] - 350s 373ms/step - loss: 2.3050 - acc: 0.1083 - val_loss: 2.3088 - val_acc: 0.1042\n",
            "Epoch 29/50\n",
            "937/937 [==============================] - 349s 372ms/step - loss: 2.3070 - acc: 0.1089 - val_loss: 2.3065 - val_acc: 0.0929\n",
            "Epoch 30/50\n",
            "937/937 [==============================] - 349s 372ms/step - loss: 2.3061 - acc: 0.1046 - val_loss: 2.3051 - val_acc: 0.1170\n",
            "Epoch 31/50\n",
            "937/937 [==============================] - 349s 373ms/step - loss: 2.3045 - acc: 0.1073 - val_loss: 2.3026 - val_acc: 0.1010\n",
            "Epoch 32/50\n",
            "937/937 [==============================] - 351s 374ms/step - loss: 2.3033 - acc: 0.1153 - val_loss: 2.3061 - val_acc: 0.1090\n",
            "Epoch 33/50\n",
            "937/937 [==============================] - 350s 373ms/step - loss: 2.3038 - acc: 0.1073 - val_loss: 2.3051 - val_acc: 0.1058\n",
            "Epoch 34/50\n",
            "937/937 [==============================] - 351s 374ms/step - loss: 2.3049 - acc: 0.1006 - val_loss: 2.3072 - val_acc: 0.1138\n",
            "Epoch 35/50\n",
            "937/937 [==============================] - 352s 376ms/step - loss: 2.3059 - acc: 0.1046 - val_loss: 2.3047 - val_acc: 0.1010\n",
            "Epoch 36/50\n",
            "937/937 [==============================] - 349s 373ms/step - loss: 2.3057 - acc: 0.1089 - val_loss: 2.3115 - val_acc: 0.0978\n",
            "Epoch 37/50\n",
            "937/937 [==============================] - 350s 374ms/step - loss: 2.3039 - acc: 0.1227 - val_loss: 2.3093 - val_acc: 0.1090\n",
            "Epoch 38/50\n",
            "937/937 [==============================] - 351s 374ms/step - loss: 2.3067 - acc: 0.1014 - val_loss: 2.3075 - val_acc: 0.1138\n",
            "Epoch 39/50\n",
            "937/937 [==============================] - 351s 375ms/step - loss: 2.3050 - acc: 0.1067 - val_loss: 2.3049 - val_acc: 0.0994\n",
            "Epoch 40/50\n",
            "937/937 [==============================] - 351s 375ms/step - loss: 2.3014 - acc: 0.1083 - val_loss: 2.3052 - val_acc: 0.0978\n",
            "Epoch 41/50\n",
            "937/937 [==============================] - 350s 374ms/step - loss: 2.3046 - acc: 0.1059 - val_loss: 2.3065 - val_acc: 0.0865\n",
            "Epoch 42/50\n",
            "937/937 [==============================] - 351s 375ms/step - loss: 2.3065 - acc: 0.1134 - val_loss: 2.3031 - val_acc: 0.0978\n",
            "Epoch 43/50\n",
            "937/937 [==============================] - 348s 372ms/step - loss: 2.3029 - acc: 0.1134 - val_loss: 2.3043 - val_acc: 0.0865\n",
            "Epoch 44/50\n",
            "937/937 [==============================] - 354s 377ms/step - loss: 2.3033 - acc: 0.1139 - val_loss: 2.3142 - val_acc: 0.0785\n",
            "Epoch 45/50\n",
            "937/937 [==============================] - 352s 375ms/step - loss: 2.3062 - acc: 0.0977 - val_loss: 2.3038 - val_acc: 0.0913\n",
            "Epoch 46/50\n",
            "937/937 [==============================] - 351s 375ms/step - loss: 2.3056 - acc: 0.1067 - val_loss: 2.3050 - val_acc: 0.1026\n",
            "Epoch 47/50\n",
            "937/937 [==============================] - 350s 374ms/step - loss: 2.3060 - acc: 0.0998 - val_loss: 2.3005 - val_acc: 0.1106\n",
            "Epoch 48/50\n",
            "937/937 [==============================] - 353s 377ms/step - loss: 2.3050 - acc: 0.1059 - val_loss: 2.3056 - val_acc: 0.0849\n",
            "Epoch 49/50\n",
            "937/937 [==============================] - 352s 376ms/step - loss: 2.3053 - acc: 0.0985 - val_loss: 2.2961 - val_acc: 0.1282\n",
            "Epoch 50/50\n",
            "937/937 [==============================] - 353s 377ms/step - loss: 2.3063 - acc: 0.1011 - val_loss: 2.3126 - val_acc: 0.0865\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fe44c5a67b8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0v0tQLx1G8SG",
        "colab_type": "code",
        "outputId": "9beb0853-7773-4891-c792-8112450b4a74",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 515
        }
      },
      "source": [
        "from keras.datasets import mnist\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.utils import np_utils\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "print(y_test.shape)\n",
        "img_rows, img_cols = 28, 28\n",
        "nb_class = 10\n",
        "x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
        "x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train/= 255\n",
        "x_test/= 255\n",
        "y_train = np_utils.to_categorical(y_train, nb_class)\n",
        "y_test = np_utils.to_categorical(y_test, nb_class)\n",
        "gen = ImageDataGenerator(rotation_range = 8,width_shift_range=0.08,shear_range= 0.3, height_shift_range= 0.08,zoom_range=0.08)\n",
        "test_gen = ImageDataGenerator()\n",
        "print(x_test.shape)                                                                                                                                         \n",
        "print(y_test.shape)\n",
        "print(x_train.shape)\n",
        "print(y_train.shape)\n",
        "train_generator = gen.flow(x_train,y_train,batch_size =4)\n",
        "test_generator = test_gen.flow(x_test,y_test,batch_size = 4)\n",
        "model.fit_generator(train_generator,steps_per_epoch =60000//64, epochs=100,validation_data= test_generator , validation_steps= 10000//64)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10000,)\n",
            "(10000, 28, 28, 1)\n",
            "(10000, 10)\n",
            "(60000, 28, 28, 1)\n",
            "(60000, 10)\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Epoch 1/100\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "813/937 [=========================>....] - ETA: 48s - loss: 14.4763 - acc: 0.1006"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}