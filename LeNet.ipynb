{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LeNet.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "MHDuxpyr7zn3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from requests import get\n",
        "\n",
        "def download_file(url, file_name):\n",
        "    with open(file_name, \"wb\") as file:\n",
        "        response = get(url)\n",
        "        file.write(response.content)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4s1Q4ZqOmS4N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "download_file('http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz', 'train-images-idx3-ubyte.gz')\n",
        "download_file('http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz', 'train-labels-idx1-ubyte.gz')\n",
        "download_file('http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz', 't10k-images-idx3-ubyte.gz')\n",
        "download_file('http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz', 't10k-labels-idx1-ubyte.gz')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z8BBJJ3ombbC",
        "colab_type": "code",
        "outputId": "00132eea-5796-4c75-b1e9-319d74d8b5e0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386
        }
      },
      "source": [
        "# Update libraries\n",
        "!pip install seaborn==0.9.0"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting seaborn==0.9.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a8/76/220ba4420459d9c4c9c9587c6ce607bf56c25b3d3d2de62056efe482dadc/seaborn-0.9.0-py3-none-any.whl (208kB)\n",
            "\u001b[K     |████████████████████████████████| 215kB 2.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy>=0.14.0 in /usr/local/lib/python3.6/dist-packages (from seaborn==0.9.0) (1.4.1)\n",
            "Requirement already satisfied: pandas>=0.15.2 in /usr/local/lib/python3.6/dist-packages (from seaborn==0.9.0) (0.25.3)\n",
            "Requirement already satisfied: matplotlib>=1.4.3 in /usr/local/lib/python3.6/dist-packages (from seaborn==0.9.0) (3.1.3)\n",
            "Requirement already satisfied: numpy>=1.9.3 in /usr/local/lib/python3.6/dist-packages (from seaborn==0.9.0) (1.17.5)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.15.2->seaborn==0.9.0) (2.6.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.15.2->seaborn==0.9.0) (2018.9)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=1.4.3->seaborn==0.9.0) (2.4.6)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=1.4.3->seaborn==0.9.0) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=1.4.3->seaborn==0.9.0) (0.10.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.6.1->pandas>=0.15.2->seaborn==0.9.0) (1.12.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from kiwisolver>=1.0.1->matplotlib>=1.4.3->seaborn==0.9.0) (45.1.0)\n",
            "Installing collected packages: seaborn\n",
            "  Found existing installation: seaborn 0.10.0\n",
            "    Uninstalling seaborn-0.10.0:\n",
            "      Successfully uninstalled seaborn-0.10.0\n",
            "Successfully installed seaborn-0.9.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ANt39Mbmiiv",
        "colab_type": "code",
        "outputId": "f91e829f-f0b2-4615-da46-a87443406cc6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 83
        }
      },
      "source": [
        "import gzip\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from time import time\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "import keras.layers as layers\n",
        "from keras.models import Sequential\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from keras.callbacks import TensorBoard\n",
        "\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "sns.set()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "byb5UObnmnsj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def read_mnist(images_path: str, labels_path: str):\n",
        "    with gzip.open(labels_path, 'rb') as labelsFile:\n",
        "        labels = np.frombuffer(labelsFile.read(), dtype=np.uint8, offset=8)\n",
        "\n",
        "    with gzip.open(images_path,'rb') as imagesFile:\n",
        "        length = len(labels)\n",
        "        # Load flat 28x28 px images (784 px), and convert them to 28x28 px\n",
        "        features = np.frombuffer(imagesFile.read(), dtype=np.uint8, offset=16) \\\n",
        "                        .reshape(length, 784) \\\n",
        "                        .reshape(length, 28, 28, 1)\n",
        "        \n",
        "    return features, labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ywEbsXawm8jb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = {}\n",
        "test = {}\n",
        "\n",
        "train['features'], train['labels'] = read_mnist('train-images-idx3-ubyte.gz', 'train-labels-idx1-ubyte.gz')\n",
        "test['features'], test['labels'] = read_mnist('t10k-images-idx3-ubyte.gz', 't10k-labels-idx1-ubyte.gz')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wA_GKq_Ym-WB",
        "colab_type": "code",
        "outputId": "ba66f3a7-1806-4d56-e1d0-164c0ae50706",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "print('# of training images:', train['features'].shape[0])\n",
        "print('# of test images:', test['features'].shape[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "# of training images: 60000\n",
            "# of test images: 10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jZtMbqIvnPBP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def display_image(position):\n",
        "    image = train['features'][position].squeeze()\n",
        "    plt.title('Example %d. Label: %d' % (position, train['labels'][position]))\n",
        "    plt.imshow(image, cmap=plt.cm.gray_r)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wGrG9rsrnR_H",
        "colab_type": "code",
        "outputId": "0f0c05ae-9e2e-4a5d-fa8f-02e7f039e2e5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        }
      },
      "source": [
        "display_image(7)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAELCAYAAAAWfFBxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qyH_7LfxojUB",
        "colab_type": "code",
        "outputId": "26836515-5751-46fd-ecf2-1cbfb8e96478",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        }
      },
      "source": [
        "display_image(10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAELCAYAAAAWfFBxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJxIUw08kKIafSFAMP5GgGH4iQf0fvCjXxD3RHu8AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FcbjoVQBopBk",
        "colab_type": "code",
        "outputId": "3168e1c0-4d88-4849-e49d-6d9c065e3266",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        }
      },
      "source": [
        "train_labels_count = np.unique(train['labels'], return_counts=True)\n",
        "dataframe_train_labels = pd.DataFrame({'Label':train_labels_count[0], 'Count':train_labels_count[1]})\n",
        "dataframe_train_labels"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Label</th>\n",
              "      <th>Count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>5923</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>6742</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>5958</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>6131</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>5842</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>5421</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>6</td>\n",
              "      <td>5918</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>7</td>\n",
              "      <td>6265</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>8</td>\n",
              "      <td>5851</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>9</td>\n",
              "      <td>5949</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Label  Count\n",
              "0      0   5923\n",
              "1      1   6742\n",
              "2      2   5958\n",
              "3      3   6131\n",
              "4      4   5842\n",
              "5      5   5421\n",
              "6      6   5918\n",
              "7      7   6265\n",
              "8      8   5851\n",
              "9      9   5949"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wv2D4DPTo1ui",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "validation = {}\n",
        "train['features'], validation['features'], train['labels'], validation['labels'] = train_test_split(train['features'], train['labels'], test_size=0.2, random_state=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B3sPhyado_32",
        "colab_type": "code",
        "outputId": "07c7e654-8ab2-4891-b09f-8d6b10d80543",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "print('# of training images:', train['features'].shape[0])\n",
        "print('# of validation images:', validation['features'].shape[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "# of training images: 48000\n",
            "# of validation images: 12000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tJ1FuMm7pBtU",
        "colab_type": "code",
        "outputId": "5211a734-db19-4062-a675-eadb3bcd52ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# Pad images with 0s\n",
        "train['features']      = np.pad(train['features'], ((0,0),(2,2),(2,2),(0,0)), 'constant')\n",
        "validation['features'] = np.pad(validation['features'], ((0,0),(2,2),(2,2),(0,0)), 'constant')\n",
        "test['features']       = np.pad(test['features'], ((0,0),(2,2),(2,2),(0,0)), 'constant')\n",
        "    \n",
        "print(\"Updated Image Shape: {}\".format(train['features'][0].shape))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Updated Image Shape: (32, 32, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y9tRZ90lpFfa",
        "colab_type": "code",
        "outputId": "d07376f7-6404-44bd-b2fd-eccad19b9913",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 184
        }
      },
      "source": [
        "model = keras.Sequential()\n",
        "\n",
        "model.add(layers.Conv2D(filters=6, kernel_size=(3, 3), activation='relu', input_shape=(32,32,1)))\n",
        "model.add(layers.AveragePooling2D())\n",
        "\n",
        "model.add(layers.Conv2D(filters=16, kernel_size=(3, 3), activation='relu'))\n",
        "model.add(layers.AveragePooling2D())\n",
        "\n",
        "model.add(layers.Flatten())\n",
        "\n",
        "model.add(layers.Dense(units=120, activation='relu'))\n",
        "\n",
        "model.add(layers.Dense(units=84, activation='relu'))\n",
        "\n",
        "model.add(layers.Dense(units=10, activation = 'softmax'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4271: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RSezVHappYvk",
        "colab_type": "code",
        "outputId": "0d296e1f-8475-4bb5-878a-b90ecbeb9932",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 30, 30, 6)         60        \n",
            "_________________________________________________________________\n",
            "average_pooling2d_1 (Average (None, 15, 15, 6)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 13, 13, 16)        880       \n",
            "_________________________________________________________________\n",
            "average_pooling2d_2 (Average (None, 6, 6, 16)          0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 576)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 120)               69240     \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 84)                10164     \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 10)                850       \n",
            "=================================================================\n",
            "Total params: 81,194\n",
            "Trainable params: 81,194\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FPmRIr3Fpacv",
        "colab_type": "code",
        "outputId": "683952fe-a142-428c-907d-a013392d5dae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        }
      },
      "source": [
        "model.compile(loss=keras.losses.categorical_crossentropy, optimizer=keras.optimizers.Adam(), metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gWuvJQZb_g1Z",
        "colab_type": "text"
      },
      "source": [
        "Epoch = 50"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vYpa7H7xpkWD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EPOCHS = 50\n",
        "BATCH_SIZE = 128"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j-HtLqyeqA3X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, y_train = train['features'], to_categorical(train['labels'])\n",
        "X_validation, y_validation = validation['features'], to_categorical(validation['labels'])\n",
        "\n",
        "train_generator = ImageDataGenerator().flow(X_train, y_train, batch_size=BATCH_SIZE)\n",
        "validation_generator = ImageDataGenerator().flow(X_validation, y_validation, batch_size=BATCH_SIZE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lRB_tf9swh3Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
        "!unzip -o ngrok-stable-linux-amd64.zip\n",
        "\n",
        "LOG_DIR = 'logs'\n",
        "get_ipython().system_raw(\n",
        "    'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'\n",
        "    .format(LOG_DIR)\n",
        ")\n",
        "\n",
        "get_ipython().system_raw('./ngrok http 6006 &')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DJ_lvGvqqWf0",
        "colab_type": "code",
        "outputId": "58c3b7d4-77bf-4bd3-f0fc-cc7e38196f02",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "print('# of training images:', train['features'].shape[0])\n",
        "print('# of validation images:', validation['features'].shape[0])\n",
        "\n",
        "steps_per_epoch = X_train.shape[0]//BATCH_SIZE\n",
        "validation_steps = X_validation.shape[0]//BATCH_SIZE\n",
        "\n",
        "tensorboard = TensorBoard(log_dir=\"logs/{}\".format(time()))\n",
        "model.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=EPOCHS, \n",
        "                    validation_data=validation_generator, validation_steps=validation_steps, \n",
        "                    shuffle=True, callbacks=[tensorboard])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "# of training images: 48000\n",
            "# of validation images: 12000\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/callbacks.py:1122: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/callbacks.py:1125: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
            "\n",
            "Epoch 1/50\n",
            "375/375 [==============================] - 23s 60ms/step - loss: 0.5323 - acc: 0.9026 - val_loss: 0.1014 - val_acc: 0.9696\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/callbacks.py:1265: The name tf.Summary is deprecated. Please use tf.compat.v1.Summary instead.\n",
            "\n",
            "Epoch 2/50\n",
            "375/375 [==============================] - 22s 59ms/step - loss: 0.0795 - acc: 0.9757 - val_loss: 0.0717 - val_acc: 0.9786\n",
            "Epoch 3/50\n",
            "375/375 [==============================] - 23s 60ms/step - loss: 0.0522 - acc: 0.9835 - val_loss: 0.0565 - val_acc: 0.9834\n",
            "Epoch 4/50\n",
            "375/375 [==============================] - 22s 59ms/step - loss: 0.0386 - acc: 0.9879 - val_loss: 0.0577 - val_acc: 0.9833\n",
            "Epoch 5/50\n",
            "375/375 [==============================] - 22s 60ms/step - loss: 0.0342 - acc: 0.9888 - val_loss: 0.0505 - val_acc: 0.9844\n",
            "Epoch 6/50\n",
            "375/375 [==============================] - 22s 59ms/step - loss: 0.0272 - acc: 0.9910 - val_loss: 0.0480 - val_acc: 0.9874\n",
            "Epoch 7/50\n",
            "375/375 [==============================] - 22s 59ms/step - loss: 0.0243 - acc: 0.9920 - val_loss: 0.0492 - val_acc: 0.9851\n",
            "Epoch 8/50\n",
            "375/375 [==============================] - 23s 61ms/step - loss: 0.0205 - acc: 0.9929 - val_loss: 0.0938 - val_acc: 0.9763\n",
            "Epoch 9/50\n",
            "375/375 [==============================] - 22s 59ms/step - loss: 0.0201 - acc: 0.9934 - val_loss: 0.0549 - val_acc: 0.9853\n",
            "Epoch 10/50\n",
            "375/375 [==============================] - 22s 59ms/step - loss: 0.0184 - acc: 0.9941 - val_loss: 0.0594 - val_acc: 0.9837\n",
            "Epoch 11/50\n",
            "375/375 [==============================] - 22s 59ms/step - loss: 0.0160 - acc: 0.9946 - val_loss: 0.0487 - val_acc: 0.9864\n",
            "Epoch 12/50\n",
            "375/375 [==============================] - 22s 60ms/step - loss: 0.0146 - acc: 0.9951 - val_loss: 0.0589 - val_acc: 0.9857\n",
            "Epoch 13/50\n",
            "375/375 [==============================] - 22s 60ms/step - loss: 0.0129 - acc: 0.9957 - val_loss: 0.0645 - val_acc: 0.9841\n",
            "Epoch 14/50\n",
            "375/375 [==============================] - 22s 59ms/step - loss: 0.0109 - acc: 0.9964 - val_loss: 0.0531 - val_acc: 0.9872\n",
            "Epoch 15/50\n",
            "375/375 [==============================] - 23s 60ms/step - loss: 0.0139 - acc: 0.9956 - val_loss: 0.0613 - val_acc: 0.9853\n",
            "Epoch 16/50\n",
            "375/375 [==============================] - 22s 58ms/step - loss: 0.0105 - acc: 0.9962 - val_loss: 0.0482 - val_acc: 0.9885\n",
            "Epoch 17/50\n",
            "375/375 [==============================] - 22s 58ms/step - loss: 0.0089 - acc: 0.9970 - val_loss: 0.0700 - val_acc: 0.9863\n",
            "Epoch 18/50\n",
            "375/375 [==============================] - 22s 57ms/step - loss: 0.0131 - acc: 0.9960 - val_loss: 0.0541 - val_acc: 0.9880\n",
            "Epoch 19/50\n",
            "375/375 [==============================] - 22s 58ms/step - loss: 0.0093 - acc: 0.9969 - val_loss: 0.0605 - val_acc: 0.9871\n",
            "Epoch 20/50\n",
            "375/375 [==============================] - 22s 58ms/step - loss: 0.0102 - acc: 0.9969 - val_loss: 0.0612 - val_acc: 0.9864\n",
            "Epoch 21/50\n",
            "375/375 [==============================] - 21s 57ms/step - loss: 0.0095 - acc: 0.9969 - val_loss: 0.0788 - val_acc: 0.9860\n",
            "Epoch 22/50\n",
            "375/375 [==============================] - 22s 59ms/step - loss: 0.0088 - acc: 0.9972 - val_loss: 0.0567 - val_acc: 0.9874\n",
            "Epoch 23/50\n",
            "375/375 [==============================] - 22s 57ms/step - loss: 0.0047 - acc: 0.9987 - val_loss: 0.0589 - val_acc: 0.9909\n",
            "Epoch 24/50\n",
            "375/375 [==============================] - 21s 57ms/step - loss: 0.0086 - acc: 0.9972 - val_loss: 0.0748 - val_acc: 0.9856\n",
            "Epoch 25/50\n",
            "375/375 [==============================] - 22s 57ms/step - loss: 0.0090 - acc: 0.9968 - val_loss: 0.0540 - val_acc: 0.9879\n",
            "Epoch 26/50\n",
            "375/375 [==============================] - 22s 57ms/step - loss: 0.0044 - acc: 0.9985 - val_loss: 0.0609 - val_acc: 0.9879\n",
            "Epoch 27/50\n",
            "375/375 [==============================] - 22s 58ms/step - loss: 0.0092 - acc: 0.9970 - val_loss: 0.0721 - val_acc: 0.9858\n",
            "Epoch 28/50\n",
            "375/375 [==============================] - 22s 58ms/step - loss: 0.0070 - acc: 0.9980 - val_loss: 0.0606 - val_acc: 0.9880\n",
            "Epoch 29/50\n",
            "375/375 [==============================] - 21s 57ms/step - loss: 0.0055 - acc: 0.9985 - val_loss: 0.0709 - val_acc: 0.9874\n",
            "Epoch 30/50\n",
            "375/375 [==============================] - 21s 57ms/step - loss: 0.0113 - acc: 0.9968 - val_loss: 0.0864 - val_acc: 0.9845\n",
            "Epoch 31/50\n",
            "375/375 [==============================] - 22s 58ms/step - loss: 0.0068 - acc: 0.9977 - val_loss: 0.0599 - val_acc: 0.9890\n",
            "Epoch 32/50\n",
            "375/375 [==============================] - 21s 57ms/step - loss: 0.0055 - acc: 0.9984 - val_loss: 0.0797 - val_acc: 0.9864\n",
            "Epoch 33/50\n",
            "375/375 [==============================] - 21s 57ms/step - loss: 0.0065 - acc: 0.9978 - val_loss: 0.0769 - val_acc: 0.9859\n",
            "Epoch 34/50\n",
            "375/375 [==============================] - 22s 58ms/step - loss: 0.0075 - acc: 0.9976 - val_loss: 0.0670 - val_acc: 0.9887\n",
            "Epoch 35/50\n",
            "375/375 [==============================] - 21s 57ms/step - loss: 0.0029 - acc: 0.9991 - val_loss: 0.0720 - val_acc: 0.9878\n",
            "Epoch 36/50\n",
            "375/375 [==============================] - 22s 58ms/step - loss: 0.0034 - acc: 0.9989 - val_loss: 0.0783 - val_acc: 0.9869\n",
            "Epoch 37/50\n",
            "375/375 [==============================] - 22s 58ms/step - loss: 0.0056 - acc: 0.9985 - val_loss: 0.0615 - val_acc: 0.9884\n",
            "Epoch 38/50\n",
            "375/375 [==============================] - 22s 57ms/step - loss: 0.0054 - acc: 0.9983 - val_loss: 0.0809 - val_acc: 0.9880\n",
            "Epoch 39/50\n",
            "375/375 [==============================] - 22s 57ms/step - loss: 0.0076 - acc: 0.9975 - val_loss: 0.0816 - val_acc: 0.9886\n",
            "Epoch 40/50\n",
            "375/375 [==============================] - 22s 58ms/step - loss: 0.0074 - acc: 0.9978 - val_loss: 0.0747 - val_acc: 0.9889\n",
            "Epoch 41/50\n",
            "375/375 [==============================] - 22s 57ms/step - loss: 0.0041 - acc: 0.9985 - val_loss: 0.0622 - val_acc: 0.9902\n",
            "Epoch 42/50\n",
            "375/375 [==============================] - 22s 58ms/step - loss: 0.0067 - acc: 0.9983 - val_loss: 0.0710 - val_acc: 0.9889\n",
            "Epoch 43/50\n",
            "375/375 [==============================] - 21s 57ms/step - loss: 0.0028 - acc: 0.9991 - val_loss: 0.0830 - val_acc: 0.9878\n",
            "Epoch 44/50\n",
            "375/375 [==============================] - 21s 57ms/step - loss: 0.0033 - acc: 0.9991 - val_loss: 0.0606 - val_acc: 0.9891\n",
            "Epoch 45/50\n",
            "375/375 [==============================] - 22s 58ms/step - loss: 0.0055 - acc: 0.9983 - val_loss: 0.0873 - val_acc: 0.9852\n",
            "Epoch 46/50\n",
            "375/375 [==============================] - 21s 57ms/step - loss: 0.0046 - acc: 0.9986 - val_loss: 0.0657 - val_acc: 0.9896\n",
            "Epoch 47/50\n",
            "375/375 [==============================] - 21s 57ms/step - loss: 0.0065 - acc: 0.9985 - val_loss: 0.0813 - val_acc: 0.9869\n",
            "Epoch 48/50\n",
            "375/375 [==============================] - 22s 57ms/step - loss: 0.0031 - acc: 0.9992 - val_loss: 0.0543 - val_acc: 0.9919\n",
            "Epoch 49/50\n",
            "375/375 [==============================] - 22s 57ms/step - loss: 0.0013 - acc: 0.9996 - val_loss: 0.0698 - val_acc: 0.9894\n",
            "Epoch 50/50\n",
            "375/375 [==============================] - 21s 57ms/step - loss: 4.5923e-04 - acc: 0.9999 - val_loss: 0.0630 - val_acc: 0.9912\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f6278ff3898>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SoV4yE2vvVDP",
        "colab_type": "code",
        "outputId": "7df84bf3-5fc6-4ba5-b99a-855e05ed8333",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "score = model.evaluate(test['features'], to_categorical(test['labels']))\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 2s 242us/step\n",
            "Test loss: 0.0653972102533246\n",
            "Test accuracy: 0.9905\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vGa4pNVTxCiN",
        "colab_type": "code",
        "outputId": "22863be6-d6c9-471e-97fc-687e5fa12c3a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "ngrok_url = !curl -s http://localhost:4040/api/tunnels | python -c \\\n",
        "    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\"\n",
        "        \n",
        "ngrok_url = ngrok_url[0].replace(\"'\", '')\n",
        "print(ngrok_url)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "http://09df9fea.ngrok.io\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3l11eb4axQcF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from IPython.display import IFrame\n",
        "\n",
        "IFrame(ngrok_url, width=700, height=900)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OlM67bOo_mn5",
        "colab_type": "text"
      },
      "source": [
        "Epoch = 100"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kX7xrLV8_qak",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EPOCHS = 100\n",
        "BATCH_SIZE = 128"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5sqH7iQ9_0eM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, y_train = train['features'], to_categorical(train['labels'])\n",
        "X_validation, y_validation = validation['features'], to_categorical(validation['labels'])\n",
        "\n",
        "train_generator = ImageDataGenerator().flow(X_train, y_train, batch_size=BATCH_SIZE)\n",
        "validation_generator = ImageDataGenerator().flow(X_validation, y_validation, batch_size=BATCH_SIZE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wy8cKHtL_4QW",
        "colab_type": "code",
        "outputId": "d0082a4a-e205-4f17-a5bb-e58e7de37a83",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "print('# of training images:', train['features'].shape[0])\n",
        "print('# of validation images:', validation['features'].shape[0])\n",
        "\n",
        "steps_per_epoch = X_train.shape[0]//BATCH_SIZE\n",
        "validation_steps = X_validation.shape[0]//BATCH_SIZE\n",
        "\n",
        "tensorboard = TensorBoard(log_dir=\"logs/{}\".format(time()))\n",
        "model.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=EPOCHS, \n",
        "                    validation_data=validation_generator, validation_steps=validation_steps, \n",
        "                    shuffle=True, callbacks=[tensorboard])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "# of training images: 48000\n",
            "# of validation images: 12000\n",
            "Epoch 1/100\n",
            "375/375 [==============================] - 22s 58ms/step - loss: 0.0025 - acc: 0.9993 - val_loss: 0.1035 - val_acc: 0.9837\n",
            "Epoch 2/100\n",
            "375/375 [==============================] - 22s 58ms/step - loss: 0.0113 - acc: 0.9972 - val_loss: 0.0728 - val_acc: 0.9891\n",
            "Epoch 3/100\n",
            "375/375 [==============================] - 22s 58ms/step - loss: 0.0037 - acc: 0.9987 - val_loss: 0.0758 - val_acc: 0.9876\n",
            "Epoch 4/100\n",
            "375/375 [==============================] - 22s 57ms/step - loss: 0.0013 - acc: 0.9997 - val_loss: 0.0718 - val_acc: 0.9889\n",
            "Epoch 5/100\n",
            "375/375 [==============================] - 22s 58ms/step - loss: 0.0019 - acc: 0.9995 - val_loss: 0.0742 - val_acc: 0.9890\n",
            "Epoch 6/100\n",
            "375/375 [==============================] - 22s 58ms/step - loss: 0.0051 - acc: 0.9986 - val_loss: 0.0795 - val_acc: 0.9869\n",
            "Epoch 7/100\n",
            "375/375 [==============================] - 22s 57ms/step - loss: 0.0048 - acc: 0.9987 - val_loss: 0.0915 - val_acc: 0.9865\n",
            "Epoch 8/100\n",
            "375/375 [==============================] - 22s 58ms/step - loss: 0.0031 - acc: 0.9991 - val_loss: 0.0862 - val_acc: 0.9877\n",
            "Epoch 9/100\n",
            "375/375 [==============================] - 22s 58ms/step - loss: 0.0066 - acc: 0.9981 - val_loss: 0.0881 - val_acc: 0.9880\n",
            "Epoch 10/100\n",
            "375/375 [==============================] - 22s 58ms/step - loss: 0.0051 - acc: 0.9987 - val_loss: 0.0899 - val_acc: 0.9861\n",
            "Epoch 11/100\n",
            "375/375 [==============================] - 21s 57ms/step - loss: 0.0062 - acc: 0.9985 - val_loss: 0.0755 - val_acc: 0.9881\n",
            "Epoch 12/100\n",
            "375/375 [==============================] - 21s 57ms/step - loss: 0.0020 - acc: 0.9994 - val_loss: 0.0709 - val_acc: 0.9907\n",
            "Epoch 13/100\n",
            "375/375 [==============================] - 22s 59ms/step - loss: 0.0015 - acc: 0.9996 - val_loss: 0.0889 - val_acc: 0.9883\n",
            "Epoch 14/100\n",
            "375/375 [==============================] - 22s 58ms/step - loss: 8.6558e-04 - acc: 0.9998 - val_loss: 0.0818 - val_acc: 0.9904\n",
            "Epoch 15/100\n",
            "375/375 [==============================] - 22s 57ms/step - loss: 3.8698e-04 - acc: 1.0000 - val_loss: 0.0809 - val_acc: 0.9906\n",
            "Epoch 16/100\n",
            "375/375 [==============================] - 22s 58ms/step - loss: 3.7633e-04 - acc: 1.0000 - val_loss: 0.0777 - val_acc: 0.9903\n",
            "Epoch 17/100\n",
            "375/375 [==============================] - 22s 58ms/step - loss: 3.4980e-04 - acc: 1.0000 - val_loss: 0.0856 - val_acc: 0.9899\n",
            "Epoch 18/100\n",
            "375/375 [==============================] - 22s 57ms/step - loss: 3.3905e-04 - acc: 1.0000 - val_loss: 0.0749 - val_acc: 0.9910\n",
            "Epoch 19/100\n",
            "375/375 [==============================] - 22s 57ms/step - loss: 3.3834e-04 - acc: 1.0000 - val_loss: 0.0852 - val_acc: 0.9902\n",
            "Epoch 20/100\n",
            "375/375 [==============================] - 22s 58ms/step - loss: 3.3793e-04 - acc: 1.0000 - val_loss: 0.0802 - val_acc: 0.9906\n",
            "Epoch 21/100\n",
            "375/375 [==============================] - 22s 58ms/step - loss: 3.3762e-04 - acc: 1.0000 - val_loss: 0.0829 - val_acc: 0.9901\n",
            "Epoch 22/100\n",
            "375/375 [==============================] - 22s 58ms/step - loss: 3.3736e-04 - acc: 1.0000 - val_loss: 0.0776 - val_acc: 0.9911\n",
            "Epoch 23/100\n",
            "375/375 [==============================] - 22s 59ms/step - loss: 3.3716e-04 - acc: 1.0000 - val_loss: 0.0895 - val_acc: 0.9896\n",
            "Epoch 24/100\n",
            "375/375 [==============================] - 22s 58ms/step - loss: 3.3698e-04 - acc: 1.0000 - val_loss: 0.0770 - val_acc: 0.9907\n",
            "Epoch 25/100\n",
            "375/375 [==============================] - 22s 58ms/step - loss: 3.3683e-04 - acc: 1.0000 - val_loss: 0.0785 - val_acc: 0.9909\n",
            "Epoch 26/100\n",
            "375/375 [==============================] - 21s 57ms/step - loss: 3.3669e-04 - acc: 1.0000 - val_loss: 0.0766 - val_acc: 0.9912\n",
            "Epoch 27/100\n",
            "375/375 [==============================] - 22s 57ms/step - loss: 3.3658e-04 - acc: 1.0000 - val_loss: 0.0810 - val_acc: 0.9907\n",
            "Epoch 28/100\n",
            "375/375 [==============================] - 22s 58ms/step - loss: 3.3648e-04 - acc: 1.0000 - val_loss: 0.0848 - val_acc: 0.9911\n",
            "Epoch 29/100\n",
            "375/375 [==============================] - 22s 57ms/step - loss: 3.3639e-04 - acc: 1.0000 - val_loss: 0.0770 - val_acc: 0.9907\n",
            "Epoch 30/100\n",
            "375/375 [==============================] - 21s 57ms/step - loss: 3.3632e-04 - acc: 1.0000 - val_loss: 0.0950 - val_acc: 0.9900\n",
            "Epoch 31/100\n",
            "375/375 [==============================] - 21s 57ms/step - loss: 3.3625e-04 - acc: 1.0000 - val_loss: 0.0773 - val_acc: 0.9912\n",
            "Epoch 32/100\n",
            "375/375 [==============================] - 21s 57ms/step - loss: 3.3620e-04 - acc: 1.0000 - val_loss: 0.0733 - val_acc: 0.9916\n",
            "Epoch 33/100\n",
            "375/375 [==============================] - 22s 58ms/step - loss: 3.3615e-04 - acc: 1.0000 - val_loss: 0.0821 - val_acc: 0.9906\n",
            "Epoch 34/100\n",
            "375/375 [==============================] - 22s 58ms/step - loss: 3.3611e-04 - acc: 1.0000 - val_loss: 0.0917 - val_acc: 0.9907\n",
            "Epoch 35/100\n",
            "375/375 [==============================] - 22s 58ms/step - loss: 3.3608e-04 - acc: 1.0000 - val_loss: 0.0798 - val_acc: 0.9907\n",
            "Epoch 36/100\n",
            "375/375 [==============================] - 22s 58ms/step - loss: 3.3605e-04 - acc: 1.0000 - val_loss: 0.0908 - val_acc: 0.9905\n",
            "Epoch 37/100\n",
            "375/375 [==============================] - 22s 58ms/step - loss: 3.3603e-04 - acc: 1.0000 - val_loss: 0.0904 - val_acc: 0.9906\n",
            "Epoch 38/100\n",
            "375/375 [==============================] - 22s 59ms/step - loss: 3.3601e-04 - acc: 1.0000 - val_loss: 0.0806 - val_acc: 0.9912\n",
            "Epoch 39/100\n",
            "375/375 [==============================] - 22s 58ms/step - loss: 3.3599e-04 - acc: 1.0000 - val_loss: 0.0764 - val_acc: 0.9923\n",
            "Epoch 40/100\n",
            "375/375 [==============================] - 22s 57ms/step - loss: 3.3598e-04 - acc: 1.0000 - val_loss: 0.0866 - val_acc: 0.9911\n",
            "Epoch 41/100\n",
            "375/375 [==============================] - 22s 58ms/step - loss: 3.3597e-04 - acc: 1.0000 - val_loss: 0.0858 - val_acc: 0.9909\n",
            "Epoch 42/100\n",
            "375/375 [==============================] - 22s 57ms/step - loss: 3.3596e-04 - acc: 1.0000 - val_loss: 0.0817 - val_acc: 0.9916\n",
            "Epoch 43/100\n",
            "375/375 [==============================] - 22s 57ms/step - loss: 3.3595e-04 - acc: 1.0000 - val_loss: 0.0821 - val_acc: 0.9914\n",
            "Epoch 44/100\n",
            "375/375 [==============================] - 22s 58ms/step - loss: 3.3594e-04 - acc: 1.0000 - val_loss: 0.0892 - val_acc: 0.9915\n",
            "Epoch 45/100\n",
            "375/375 [==============================] - 22s 58ms/step - loss: 3.3594e-04 - acc: 1.0000 - val_loss: 0.0961 - val_acc: 0.9904\n",
            "Epoch 46/100\n",
            "375/375 [==============================] - 22s 57ms/step - loss: 3.3593e-04 - acc: 1.0000 - val_loss: 0.0817 - val_acc: 0.9922\n",
            "Epoch 47/100\n",
            "375/375 [==============================] - 22s 58ms/step - loss: 3.3593e-04 - acc: 1.0000 - val_loss: 0.0842 - val_acc: 0.9908\n",
            "Epoch 48/100\n",
            "375/375 [==============================] - 22s 58ms/step - loss: 3.3593e-04 - acc: 1.0000 - val_loss: 0.0977 - val_acc: 0.9907\n",
            "Epoch 49/100\n",
            "375/375 [==============================] - 22s 58ms/step - loss: 3.3592e-04 - acc: 1.0000 - val_loss: 0.0813 - val_acc: 0.9916\n",
            "Epoch 50/100\n",
            "375/375 [==============================] - 22s 58ms/step - loss: 3.3592e-04 - acc: 1.0000 - val_loss: 0.1000 - val_acc: 0.9907\n",
            "Epoch 51/100\n",
            "375/375 [==============================] - 22s 57ms/step - loss: 3.3592e-04 - acc: 1.0000 - val_loss: 0.0820 - val_acc: 0.9917\n",
            "Epoch 52/100\n",
            "375/375 [==============================] - 23s 60ms/step - loss: 3.3592e-04 - acc: 1.0000 - val_loss: 0.0792 - val_acc: 0.9925\n",
            "Epoch 53/100\n",
            "375/375 [==============================] - 22s 59ms/step - loss: 3.3592e-04 - acc: 1.0000 - val_loss: 0.0896 - val_acc: 0.9912\n",
            "Epoch 54/100\n",
            "375/375 [==============================] - 22s 58ms/step - loss: 3.3592e-04 - acc: 1.0000 - val_loss: 0.0919 - val_acc: 0.9907\n",
            "Epoch 55/100\n",
            "375/375 [==============================] - 22s 58ms/step - loss: 3.3592e-04 - acc: 1.0000 - val_loss: 0.0836 - val_acc: 0.9921\n",
            "Epoch 56/100\n",
            "375/375 [==============================] - 22s 60ms/step - loss: 3.3591e-04 - acc: 1.0000 - val_loss: 0.0993 - val_acc: 0.9906\n",
            "Epoch 57/100\n",
            "375/375 [==============================] - 22s 58ms/step - loss: 3.3591e-04 - acc: 1.0000 - val_loss: 0.0945 - val_acc: 0.9912\n",
            "Epoch 58/100\n",
            "375/375 [==============================] - 22s 58ms/step - loss: 3.3591e-04 - acc: 1.0000 - val_loss: 0.0840 - val_acc: 0.9917\n",
            "Epoch 59/100\n",
            "375/375 [==============================] - 22s 58ms/step - loss: 3.3591e-04 - acc: 1.0000 - val_loss: 0.0960 - val_acc: 0.9911\n",
            "Epoch 60/100\n",
            "375/375 [==============================] - 22s 58ms/step - loss: 3.3591e-04 - acc: 1.0000 - val_loss: 0.0876 - val_acc: 0.9916\n",
            "Epoch 61/100\n",
            "375/375 [==============================] - 22s 58ms/step - loss: 3.3591e-04 - acc: 1.0000 - val_loss: 0.0920 - val_acc: 0.9912\n",
            "Epoch 62/100\n",
            "375/375 [==============================] - 21s 57ms/step - loss: 3.3591e-04 - acc: 1.0000 - val_loss: 0.0943 - val_acc: 0.9912\n",
            "Epoch 63/100\n",
            "375/375 [==============================] - 22s 58ms/step - loss: 3.3591e-04 - acc: 1.0000 - val_loss: 0.0884 - val_acc: 0.9918\n",
            "Epoch 64/100\n",
            "375/375 [==============================] - 22s 58ms/step - loss: 3.3591e-04 - acc: 1.0000 - val_loss: 0.0898 - val_acc: 0.9912\n",
            "Epoch 65/100\n",
            "375/375 [==============================] - 22s 57ms/step - loss: 3.3591e-04 - acc: 1.0000 - val_loss: 0.0987 - val_acc: 0.9912\n",
            "Epoch 66/100\n",
            "375/375 [==============================] - 22s 58ms/step - loss: 3.3591e-04 - acc: 1.0000 - val_loss: 0.0946 - val_acc: 0.9911\n",
            "Epoch 67/100\n",
            "375/375 [==============================] - 22s 59ms/step - loss: 3.3591e-04 - acc: 1.0000 - val_loss: 0.0904 - val_acc: 0.9910\n",
            "Epoch 68/100\n",
            "375/375 [==============================] - 22s 58ms/step - loss: 3.3591e-04 - acc: 1.0000 - val_loss: 0.1006 - val_acc: 0.9907\n",
            "Epoch 69/100\n",
            "375/375 [==============================] - 22s 58ms/step - loss: 3.3591e-04 - acc: 1.0000 - val_loss: 0.0852 - val_acc: 0.9918\n",
            "Epoch 70/100\n",
            "375/375 [==============================] - 22s 58ms/step - loss: 3.3591e-04 - acc: 1.0000 - val_loss: 0.0932 - val_acc: 0.9912\n",
            "Epoch 71/100\n",
            "375/375 [==============================] - 22s 58ms/step - loss: 3.3591e-04 - acc: 1.0000 - val_loss: 0.1026 - val_acc: 0.9902\n",
            "Epoch 72/100\n",
            "375/375 [==============================] - 22s 58ms/step - loss: 3.3591e-04 - acc: 1.0000 - val_loss: 0.0898 - val_acc: 0.9916\n",
            "Epoch 73/100\n",
            "375/375 [==============================] - 22s 58ms/step - loss: 3.3591e-04 - acc: 1.0000 - val_loss: 0.0932 - val_acc: 0.9913\n",
            "Epoch 74/100\n",
            "375/375 [==============================] - 22s 58ms/step - loss: 3.3591e-04 - acc: 1.0000 - val_loss: 0.0956 - val_acc: 0.9912\n",
            "Epoch 75/100\n",
            "375/375 [==============================] - 22s 58ms/step - loss: 3.3591e-04 - acc: 1.0000 - val_loss: 0.0960 - val_acc: 0.9907\n",
            "Epoch 76/100\n",
            "375/375 [==============================] - 22s 58ms/step - loss: 3.3591e-04 - acc: 1.0000 - val_loss: 0.0874 - val_acc: 0.9917\n",
            "Epoch 77/100\n",
            "375/375 [==============================] - 22s 58ms/step - loss: 3.3591e-04 - acc: 1.0000 - val_loss: 0.0998 - val_acc: 0.9911\n",
            "Epoch 78/100\n",
            "375/375 [==============================] - 22s 58ms/step - loss: 3.3591e-04 - acc: 1.0000 - val_loss: 0.0897 - val_acc: 0.9913\n",
            "Epoch 79/100\n",
            "375/375 [==============================] - 22s 58ms/step - loss: 3.3591e-04 - acc: 1.0000 - val_loss: 0.0934 - val_acc: 0.9912\n",
            "Epoch 80/100\n",
            "375/375 [==============================] - 22s 58ms/step - loss: 3.3591e-04 - acc: 1.0000 - val_loss: 0.0950 - val_acc: 0.9912\n",
            "Epoch 81/100\n",
            "375/375 [==============================] - 22s 60ms/step - loss: 3.3591e-04 - acc: 1.0000 - val_loss: 0.0977 - val_acc: 0.9907\n",
            "Epoch 82/100\n",
            "375/375 [==============================] - 22s 58ms/step - loss: 3.3591e-04 - acc: 1.0000 - val_loss: 0.0974 - val_acc: 0.9912\n",
            "Epoch 83/100\n",
            "375/375 [==============================] - 22s 58ms/step - loss: 3.3591e-04 - acc: 1.0000 - val_loss: 0.0935 - val_acc: 0.9909\n",
            "Epoch 84/100\n",
            "375/375 [==============================] - 22s 57ms/step - loss: 3.3591e-04 - acc: 1.0000 - val_loss: 0.0907 - val_acc: 0.9916\n",
            "Epoch 85/100\n",
            "375/375 [==============================] - 22s 58ms/step - loss: 3.3591e-04 - acc: 1.0000 - val_loss: 0.0926 - val_acc: 0.9912\n",
            "Epoch 86/100\n",
            "375/375 [==============================] - 22s 58ms/step - loss: 3.3591e-04 - acc: 1.0000 - val_loss: 0.0916 - val_acc: 0.9912\n",
            "Epoch 87/100\n",
            "375/375 [==============================] - 22s 58ms/step - loss: 3.3591e-04 - acc: 1.0000 - val_loss: 0.0979 - val_acc: 0.9909\n",
            "Epoch 88/100\n",
            "375/375 [==============================] - 22s 58ms/step - loss: 3.3591e-04 - acc: 1.0000 - val_loss: 0.0918 - val_acc: 0.9911\n",
            "Epoch 89/100\n",
            "375/375 [==============================] - 22s 58ms/step - loss: 3.3591e-04 - acc: 1.0000 - val_loss: 0.0986 - val_acc: 0.9907\n",
            "Epoch 90/100\n",
            "375/375 [==============================] - 22s 58ms/step - loss: 3.3591e-04 - acc: 1.0000 - val_loss: 0.0942 - val_acc: 0.9909\n",
            "Epoch 91/100\n",
            "375/375 [==============================] - 22s 58ms/step - loss: 3.3591e-04 - acc: 1.0000 - val_loss: 0.0950 - val_acc: 0.9911\n",
            "Epoch 92/100\n",
            "375/375 [==============================] - 22s 58ms/step - loss: 3.3591e-04 - acc: 1.0000 - val_loss: 0.0949 - val_acc: 0.9909\n",
            "Epoch 93/100\n",
            "375/375 [==============================] - 22s 58ms/step - loss: 3.3591e-04 - acc: 1.0000 - val_loss: 0.0940 - val_acc: 0.9912\n",
            "Epoch 94/100\n",
            "375/375 [==============================] - 22s 58ms/step - loss: 3.3591e-04 - acc: 1.0000 - val_loss: 0.0942 - val_acc: 0.9910\n",
            "Epoch 95/100\n",
            "375/375 [==============================] - 22s 59ms/step - loss: 3.3591e-04 - acc: 1.0000 - val_loss: 0.0953 - val_acc: 0.9909\n",
            "Epoch 96/100\n",
            "375/375 [==============================] - 22s 58ms/step - loss: 3.3591e-04 - acc: 1.0000 - val_loss: 0.0955 - val_acc: 0.9909\n",
            "Epoch 97/100\n",
            "375/375 [==============================] - 22s 58ms/step - loss: 3.3591e-04 - acc: 1.0000 - val_loss: 0.0925 - val_acc: 0.9913\n",
            "Epoch 98/100\n",
            "375/375 [==============================] - 22s 58ms/step - loss: 3.3591e-04 - acc: 1.0000 - val_loss: 0.0926 - val_acc: 0.9911\n",
            "Epoch 99/100\n",
            "375/375 [==============================] - 22s 58ms/step - loss: 3.3591e-04 - acc: 1.0000 - val_loss: 0.0990 - val_acc: 0.9906\n",
            "Epoch 100/100\n",
            "375/375 [==============================] - 22s 58ms/step - loss: 3.3591e-04 - acc: 1.0000 - val_loss: 0.0902 - val_acc: 0.9912\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f626d3fc240>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZZfdZO_KKA3X",
        "colab_type": "code",
        "outputId": "a98dcca8-4eef-462a-84fe-577d4e69927e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "score = model.evaluate(test['features'], to_categorical(test['labels']))\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 2s 243us/step\n",
            "Test loss: 0.08564416719894388\n",
            "Test accuracy: 0.9909\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}